{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tensorflow dataset\n",
    "- Simple LSTM Network\n",
    "- Long sequences to short chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.0MB 3.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas) (2.8.0)\n",
      "Collecting pytz>=2011k (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 3.7MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from pandas) (1.16.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.5/dist-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-0.24.2 pytz-2019.3\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mne\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/af/9c64ac8f75b1c932ca5fb16bc27740cd9b9817f9173a6608ae999e82bb6a/mne-0.20.0-py3-none-any.whl (6.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.6MB 2.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.5/dist-packages (from mne) (1.16.1)\n",
      "Collecting scipy>=0.17.1 (from mne)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/60/8cbf00c0deb50a971e6e3a015fb32513960a92867df979870a454481817c/scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.0MB 715kB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: scipy, mne\n",
      "Successfully installed mne-0.20.0 scipy-1.4.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/ec/32310181e803f5d22e0dd33eb18924489b2f8d08cf5b6e116a93a6a5d1c6/scikit_learn-0.22.2.post1-cp35-cp35m-manylinux1_x86_64.whl (7.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.0MB 3.2MB/s eta 0:00:01    59% |███████████████████             | 4.2MB 5.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.5/dist-packages (from scikit-learn) (1.4.1)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 12.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.5/dist-packages (from scikit-learn) (1.16.1)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.2.post1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/86/43b8c9138ef4c2a1c492fee92792c83c13799d0e2061ff810d3826d06cd1/seaborn-0.9.1-py2.py3-none-any.whl (216kB)\n",
      "\u001b[K    100% |████████████████████████████████| 225kB 3.3MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.5/dist-packages (from seaborn) (1.16.1)\n",
      "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.5/dist-packages (from seaborn) (0.24.2)\n",
      "Requirement already satisfied: matplotlib>=1.5.3 in /usr/local/lib/python3.5/dist-packages (from seaborn) (3.0.2)\n",
      "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.5/dist-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.5/dist-packages (from pandas>=0.17.1->seaborn) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas>=0.17.1->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.5.3->seaborn) (2.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.5.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.5.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.5/dist-packages (from python-dateutil>=2.5.0->pandas>=0.17.1->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.3->seaborn) (40.8.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.9.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 6.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras) (1.16.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.9)\n",
      "Collecting pyyaml (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K    100% |████████████████████████████████| 276kB 12.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.7)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, keras\n",
      "Successfully installed keras-2.3.1 pyyaml-5.3.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 876kB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.45.0\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие каналы содержат "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "- Один сэмпл содержит чанк сигнала, чанки не пересекаются\n",
    "- Считывание происходит из случайных файлов из списка\n",
    "- Чанки рандомизированы:\n",
    "    - Учесть рандомизацию по номеру пациента, сессии, времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"file\", \"start\", \"end\", \"label\", \"confidence\"]\n",
    "train_df = pd.read_csv(\"../_DOCS/ref_train.txt\", sep=\" \", names=header)\n",
    "val_df = pd.read_csv(\"../_DOCS/ref_dev.txt\", sep=\" \", names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(full_file):\n",
    "    parts = full_file.split(\"_\")\n",
    "    patient = int(parts[0])\n",
    "    session = int(parts[1][1:])\n",
    "    file = int(parts[2][1:])\n",
    "    return [patient, session, file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[258, 2, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_file(\"00000258_s002_t000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_file_info(df):\n",
    "    values = np.array(df[\"file\"].apply(preprocess_file).tolist())\n",
    "    files_df = pd.DataFrame(values, columns=[\"patient\", \"session\", \"chunk\"], index=df.index)\n",
    "    return df.merge(files_df, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = append_file_info(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = append_file_info(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO add other electrode formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_files(df, dataset):\n",
    "    paths = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(\"../edf/{}\".format(dataset)):\n",
    "        path = root.split(os.sep)\n",
    "        for file in files:\n",
    "            if \".edf\" in file:\n",
    "                name = file.split(\".\")[0]\n",
    "                paths[name] = os.path.abspath(root) + \"/\" +  file\n",
    "    \n",
    "    df[\"full_path\"] = df[\"file\"].apply(paths.get)\n",
    "    return df[df[\"full_path\"].apply(lambda x: \"01_tcp_ar\" in x)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = attach_files(train_df, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = attach_files(val_df, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove bckg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bckg_files(df):\n",
    "    files_with_seizures = df[df[\"label\"] == \"seiz\"][\"file\"].unique()\n",
    "    return df[df[\"file\"].isin(files_with_seizures)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = remove_bckg_files(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = remove_bckg_files(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate channels intersection and proper sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edf_info(df):\n",
    "    files = df[\"full_path\"].unique()\n",
    "\n",
    "    edf_data = []\n",
    "\n",
    "    for file in tqdm_notebook(files):\n",
    "        edf = mne.io.read_raw_edf(file, verbose=\"ERROR\")\n",
    "        data = {\n",
    "            field: edf.info[field]\n",
    "            for field in [\"ch_names\", \"sfreq\"]\n",
    "        }\n",
    "        edf_data.append(data)\n",
    "        \n",
    "    return pd.DataFrame(edf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c2229edd93485db662185a560f9b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=458.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_edf_df = get_edf_info(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61187da434284e09a8d5a3961f4a38c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_edf_df = get_edf_info(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_FREQUENCY = int(min(train_edf_df[\"sfreq\"].min(), val_edf_df[\"sfreq\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter([\n",
    "    channel for channels_list in train_edf_df[\"ch_names\"] for channel in channels_list\n",
    "] + [\n",
    "    channel for channels_list in val_edf_df[\"ch_names\"] for channel in channels_list\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels = dict(counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_limit = max([v for k, v in all_channels.items() if \"STI\" not in k])\n",
    "CHANNELS = [k for k, v in all_channels.items() if v >= usage_limit and \"STI\" not in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STIM_CHANNEL = [k for k in all_channels.keys() if \"STI\" in k][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"duration\"] = train_df[\"end\"] - train_df[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "bckg    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "seiz    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: duration, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.groupby('label')[\"duration\"].plot(kind=\"hist\", bins=np.linspace(0, 50), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_TIME = 1 * CHUNK_FREQUENCY # number of terms per chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split on chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get all file names, randomize them\n",
    "- For each file - split on chunks, randomize them\n",
    "- Get labels for each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fourier_transform(data, window_size=CHUNK_TIME, step_size=CHUNK_TIME // 10):\n",
    "    data = data.T\n",
    "    frequencies = []\n",
    "    for window in range(0, data.shape[0] - window_size, step_size):\n",
    "        chunk = data[window:window + window_size]\n",
    "        frequency_values = np.abs(np.fft.fft(chunk, axis=0))[:window_size // 2]\n",
    "        frequencies.append(frequency_values)\n",
    "    result = np.stack(frequencies)\n",
    "    return result.reshape(result.shape[0], -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, file, channels=CHANNELS, chunk_size=CHUNK_TIME):\n",
    "    annotations = df[\n",
    "        (df[\"full_path\"] == file) & \\\n",
    "        (df[\"label\"] == \"seiz\")\n",
    "    ][[\"start\", \"end\"]]\n",
    "    edf = mne.io.read_raw_edf(file, preload=True, verbose='ERROR')\n",
    "    edf.filter(2, 60)\n",
    "    edf_picks = edf.pick_channels(channels)\n",
    "    data, time = edf_picks[:]\n",
    "        \n",
    "    events = time * 0\n",
    "    for _, (start, end) in annotations.iterrows():\n",
    "        events += (time >= start) & (time <= end)\n",
    "    events = (events > 0).astype(int)\n",
    "    \n",
    "    return data, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_multiple(df, files, channels=CHANNELS, chunk_size=CHUNK_TIME):\n",
    "    total_data = []\n",
    "    total_events = []\n",
    "    for file in tqdm_notebook(files):\n",
    "        data, events = get_data(df, file)\n",
    "        total_data.append(data)\n",
    "        total_events.append(events)\n",
    "    \n",
    "    min_length = min([e.shape[0] for e in total_events])\n",
    "    truncated_length = (min_length // chunk_size) * chunk_size\n",
    "    total_data = [d[:, :truncated_length] for d in total_data]\n",
    "    total_events = [e[:truncated_length] for e in total_events]\n",
    "    \n",
    "    total_data = [\n",
    "        get_fourier_transform(d)\n",
    "        for d in total_data\n",
    "    ]\n",
    "    \n",
    "    return np.stack(total_data), np.stack(total_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_chunks(data, events, chunk_size=CHUNK_TIME):\n",
    "    max_time = max([e.shape[0] for e in events])\n",
    "    while True:\n",
    "        for chunk_start in range(0, max_time - chunk_size, chunk_size // 10):\n",
    "            data_chunk = [d[:, chunk_start:chunk_start + chunk_size].T for d in data]\n",
    "\n",
    "            labels_chunk = [e[chunk_start:chunk_start + chunk_size] for e in events]\n",
    "\n",
    "            yield np.stack(data_chunk), np.stack(labels_chunk)[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_files(df, batch_size=BATCH_SIZE):\n",
    "    files = df[\"full_path\"].unique()\n",
    "    files = np.random.choice(files, len(files), replace=False)\n",
    "    for files in zip(*[iter(files)]*batch_size):\n",
    "        yield files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = next(iterate_files(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, events = get_data(train_df, files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeffdea23f254ff89995e67a6a36a356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = train_df[\"full_path\"].value_counts().index[0:32]\n",
    "data, events = get_data_multiple(train_df, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 314500)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iterate_chunks(data, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk, labels_chunk = next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 250, 2625)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_chunk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чанк для LSTM: (BATCH_SIZE x CHUNK_TIME x FREQUENCIES * CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_SIZE = 128\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_FILTERS = (8, 16, 32, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ли добавить CNN?\n",
    "- Conv1D: (BATCH_SIZE, CHUNK_TIME, CHANNELS) -> (BATCH_SIZE, CHUNK_TIME, CNN_FILTERS)\n",
    "- MaxPool1D: (BATCH_SIZE, CHUNK_TIME, CNN_FILTERS) -> (BATCH_SIZE, CHUNK_TIME // POOL_SIZE, CNN_FILTERS)\n",
    "\n",
    "Продолжать до тех пор, пока чанка не станет достаточного размера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.layers import LSTM,Bidirectional #could try TimeDistributed(Dense(...))\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import optimizers,regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend.tensorflow_backend as KTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, batch_input_shape=(32, 250, ..., kernel_regularizer=<keras.reg...)`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,W_regularizer=regularizers.l2(l=0.01), batch_input_shape=(BATCH_SIZE, CHUNK_TIME, CHUNK_TIME // 2 * len(CHANNELS))))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True, stateful=False)))#, input_shape=(seqlength, features)) ) ### bidirectional ---><---\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu',W_regularizer=regularizers.l2(l=0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy', recall_m, precision_m]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit on small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO add validation\n",
    "- TODO make batch\n",
    "- TODO speed up iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO make model converge on this batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = iterate_chunks(data, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(generator)\n",
    "x, y_end = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025125"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_end.sum() / (y_end > -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5002788"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)[3].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "32/32 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.974715232849121, 0.06475000083446503, 1.0, 0.02616165578365326]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x, y_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "32/32 [==============================] - 1s 28ms/step - loss: 2.0608 - accuracy: 0.6528 - recall_m: 0.2736 - precision_m: 0.0205\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 2.0369 - accuracy: 0.4711 - recall_m: 0.7512 - precision_m: 0.0349\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9833 - accuracy: 0.4689 - recall_m: 0.7612 - precision_m: 0.0351\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.9311 - accuracy: 0.5395 - recall_m: 0.7363 - precision_m: 0.0392\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.8939 - accuracy: 0.5828 - recall_m: 0.5970 - precision_m: 0.0355\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.8586 - accuracy: 0.6176 - recall_m: 0.4975 - precision_m: 0.0327\n",
      "Epoch 7/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.8087 - accuracy: 0.6364 - recall_m: 0.5323 - precision_m: 0.0366\n",
      "Epoch 8/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.7699 - accuracy: 0.6711 - recall_m: 0.5821 - precision_m: 0.0439\n",
      "Epoch 9/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.7294 - accuracy: 0.6488 - recall_m: 0.6567 - precision_m: 0.0459\n",
      "Epoch 10/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.6942 - accuracy: 0.6403 - recall_m: 0.6866 - precision_m: 0.0467\n",
      "Epoch 11/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.6598 - accuracy: 0.6494 - recall_m: 0.6517 - precision_m: 0.0457\n",
      "Epoch 12/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 1.6257 - accuracy: 0.6864 - recall_m: 0.6368 - precision_m: 0.0499\n",
      "Epoch 13/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.5887 - accuracy: 0.7340 - recall_m: 0.5771 - precision_m: 0.0537\n",
      "Epoch 14/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.5553 - accuracy: 0.7580 - recall_m: 0.5423 - precision_m: 0.0558\n",
      "Epoch 15/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.5216 - accuracy: 0.7875 - recall_m: 0.5025 - precision_m: 0.0594\n",
      "Epoch 16/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.4930 - accuracy: 0.8195 - recall_m: 0.4179 - precision_m: 0.0595\n",
      "Epoch 17/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.4655 - accuracy: 0.8331 - recall_m: 0.3682 - precision_m: 0.0577\n",
      "Epoch 18/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.4313 - accuracy: 0.8307 - recall_m: 0.4826 - precision_m: 0.0720\n",
      "Epoch 19/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.4048 - accuracy: 0.8571 - recall_m: 0.4776 - precision_m: 0.0847\n",
      "Epoch 20/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3762 - accuracy: 0.8579 - recall_m: 0.4975 - precision_m: 0.0880\n",
      "Epoch 21/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.3475 - accuracy: 0.8580 - recall_m: 0.5174 - precision_m: 0.0910\n",
      "Epoch 22/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3221 - accuracy: 0.8751 - recall_m: 0.5174 - precision_m: 0.1034\n",
      "Epoch 23/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.3008 - accuracy: 0.8855 - recall_m: 0.4776 - precision_m: 0.1058\n",
      "Epoch 24/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2720 - accuracy: 0.9035 - recall_m: 0.5025 - precision_m: 0.1307\n",
      "Epoch 25/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.2490 - accuracy: 0.9046 - recall_m: 0.4577 - precision_m: 0.1233\n",
      "Epoch 26/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2246 - accuracy: 0.9162 - recall_m: 0.4428 - precision_m: 0.1376\n",
      "Epoch 27/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.2043 - accuracy: 0.9221 - recall_m: 0.4826 - precision_m: 0.1575\n",
      "Epoch 28/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1797 - accuracy: 0.9310 - recall_m: 0.4776 - precision_m: 0.1768\n",
      "Epoch 29/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.1611 - accuracy: 0.9304 - recall_m: 0.4776 - precision_m: 0.1752\n",
      "Epoch 30/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1378 - accuracy: 0.9293 - recall_m: 0.5025 - precision_m: 0.1781\n",
      "Epoch 31/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.1220 - accuracy: 0.9239 - recall_m: 0.4975 - precision_m: 0.1645\n",
      "Epoch 32/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.1026 - accuracy: 0.9293 - recall_m: 0.5323 - precision_m: 0.1848\n",
      "Epoch 33/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0835 - accuracy: 0.9355 - recall_m: 0.5124 - precision_m: 0.1977\n",
      "Epoch 34/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0670 - accuracy: 0.9388 - recall_m: 0.4876 - precision_m: 0.2021\n",
      "Epoch 35/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0482 - accuracy: 0.9405 - recall_m: 0.5025 - precision_m: 0.2117\n",
      "Epoch 36/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 1.0278 - accuracy: 0.9369 - recall_m: 0.4975 - precision_m: 0.1984\n",
      "Epoch 37/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 1.0139 - accuracy: 0.9367 - recall_m: 0.5224 - precision_m: 0.2039\n",
      "Epoch 38/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9950 - accuracy: 0.9405 - recall_m: 0.6020 - precision_m: 0.2340\n",
      "Epoch 39/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9806 - accuracy: 0.9438 - recall_m: 0.5672 - precision_m: 0.2390\n",
      "Epoch 40/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.9639 - accuracy: 0.9451 - recall_m: 0.5572 - precision_m: 0.2424\n",
      "Epoch 41/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9475 - accuracy: 0.9451 - recall_m: 0.5721 - precision_m: 0.2457\n",
      "Epoch 42/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9348 - accuracy: 0.9444 - recall_m: 0.5373 - precision_m: 0.2348\n",
      "Epoch 43/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9196 - accuracy: 0.9450 - recall_m: 0.6269 - precision_m: 0.2566\n",
      "Epoch 44/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.9044 - accuracy: 0.9492 - recall_m: 0.6219 - precision_m: 0.2747\n",
      "Epoch 45/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8910 - accuracy: 0.9516 - recall_m: 0.6318 - precision_m: 0.2886\n",
      "Epoch 46/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8778 - accuracy: 0.9505 - recall_m: 0.5771 - precision_m: 0.2717\n",
      "Epoch 47/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8624 - accuracy: 0.9501 - recall_m: 0.6816 - precision_m: 0.2903\n",
      "Epoch 48/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8481 - accuracy: 0.9531 - recall_m: 0.6915 - precision_m: 0.3075\n",
      "Epoch 49/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.8349 - accuracy: 0.9617 - recall_m: 0.6169 - precision_m: 0.3513\n",
      "Epoch 50/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8231 - accuracy: 0.9563 - recall_m: 0.6169 - precision_m: 0.3123\n",
      "Epoch 51/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.8105 - accuracy: 0.9510 - recall_m: 0.7015 - precision_m: 0.2981\n",
      "Epoch 52/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7970 - accuracy: 0.9539 - recall_m: 0.7065 - precision_m: 0.3142\n",
      "Epoch 53/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7859 - accuracy: 0.9557 - recall_m: 0.6219 - precision_m: 0.3102\n",
      "Epoch 54/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7725 - accuracy: 0.9580 - recall_m: 0.7065 - precision_m: 0.3389\n",
      "Epoch 55/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7614 - accuracy: 0.9588 - recall_m: 0.7612 - precision_m: 0.3517\n",
      "Epoch 56/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7510 - accuracy: 0.9589 - recall_m: 0.6219 - precision_m: 0.3307\n",
      "Epoch 57/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7385 - accuracy: 0.9578 - recall_m: 0.7015 - precision_m: 0.3365\n",
      "Epoch 58/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7277 - accuracy: 0.9588 - recall_m: 0.7662 - precision_m: 0.3524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.7163 - accuracy: 0.9615 - recall_m: 0.7164 - precision_m: 0.3646\n",
      "Epoch 60/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.7058 - accuracy: 0.9609 - recall_m: 0.7114 - precision_m: 0.3593\n",
      "Epoch 61/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6954 - accuracy: 0.9589 - recall_m: 0.7065 - precision_m: 0.3447\n",
      "Epoch 62/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6844 - accuracy: 0.9603 - recall_m: 0.7264 - precision_m: 0.3570\n",
      "Epoch 63/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6744 - accuracy: 0.9613 - recall_m: 0.7363 - precision_m: 0.3654\n",
      "Epoch 64/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6652 - accuracy: 0.9619 - recall_m: 0.6318 - precision_m: 0.3547\n",
      "Epoch 65/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6550 - accuracy: 0.9592 - recall_m: 0.7711 - precision_m: 0.3563\n",
      "Epoch 66/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6488 - accuracy: 0.9750 - recall_m: 0.2687 - precision_m: 0.5047\n",
      "Epoch 67/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6447 - accuracy: 0.9501 - recall_m: 0.8507 - precision_m: 0.3167\n",
      "Epoch 68/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6259 - accuracy: 0.9669 - recall_m: 0.5622 - precision_m: 0.3897\n",
      "Epoch 69/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.6187 - accuracy: 0.9734 - recall_m: 0.2488 - precision_m: 0.4464\n",
      "Epoch 70/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.6094 - accuracy: 0.9610 - recall_m: 0.8060 - precision_m: 0.3724\n",
      "Epoch 71/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5989 - accuracy: 0.9636 - recall_m: 0.6965 - precision_m: 0.3784\n",
      "Epoch 72/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5915 - accuracy: 0.9754 - recall_m: 0.2886 - precision_m: 0.5179\n",
      "Epoch 73/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5798 - accuracy: 0.9691 - recall_m: 0.5920 - precision_m: 0.4190\n",
      "Epoch 74/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5742 - accuracy: 0.9599 - recall_m: 0.7363 - precision_m: 0.3558\n",
      "Epoch 75/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5630 - accuracy: 0.9651 - recall_m: 0.6716 - precision_m: 0.3879\n",
      "Epoch 76/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5558 - accuracy: 0.9751 - recall_m: 0.3682 - precision_m: 0.5068\n",
      "Epoch 77/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5462 - accuracy: 0.9678 - recall_m: 0.5672 - precision_m: 0.4000\n",
      "Epoch 78/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5405 - accuracy: 0.9621 - recall_m: 0.7363 - precision_m: 0.3719\n",
      "Epoch 79/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5298 - accuracy: 0.9671 - recall_m: 0.6368 - precision_m: 0.4025\n",
      "Epoch 80/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.5230 - accuracy: 0.9749 - recall_m: 0.3682 - precision_m: 0.5000\n",
      "Epoch 81/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.5140 - accuracy: 0.9712 - recall_m: 0.4328 - precision_m: 0.4286\n",
      "Epoch 82/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.5064 - accuracy: 0.9656 - recall_m: 0.7264 - precision_m: 0.3989\n",
      "Epoch 83/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4985 - accuracy: 0.9666 - recall_m: 0.6766 - precision_m: 0.4024\n",
      "Epoch 84/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4911 - accuracy: 0.9753 - recall_m: 0.4328 - precision_m: 0.5088\n",
      "Epoch 85/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4836 - accuracy: 0.9726 - recall_m: 0.4925 - precision_m: 0.4583\n",
      "Epoch 86/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4768 - accuracy: 0.9691 - recall_m: 0.6318 - precision_m: 0.4233\n",
      "Epoch 87/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4691 - accuracy: 0.9709 - recall_m: 0.6219 - precision_m: 0.4433\n",
      "Epoch 88/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4614 - accuracy: 0.9745 - recall_m: 0.4677 - precision_m: 0.4921\n",
      "Epoch 89/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4560 - accuracy: 0.9710 - recall_m: 0.4378 - precision_m: 0.4251\n",
      "Epoch 90/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4479 - accuracy: 0.9699 - recall_m: 0.6318 - precision_m: 0.4320\n",
      "Epoch 91/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4405 - accuracy: 0.9732 - recall_m: 0.5920 - precision_m: 0.4741\n",
      "Epoch 92/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4342 - accuracy: 0.9754 - recall_m: 0.4527 - precision_m: 0.5112\n",
      "Epoch 93/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4272 - accuracy: 0.9721 - recall_m: 0.5672 - precision_m: 0.4560\n",
      "Epoch 94/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4200 - accuracy: 0.9750 - recall_m: 0.5572 - precision_m: 0.5022\n",
      "Epoch 95/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4138 - accuracy: 0.9750 - recall_m: 0.4826 - precision_m: 0.5026\n",
      "Epoch 96/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.4078 - accuracy: 0.9740 - recall_m: 0.5423 - precision_m: 0.4844\n",
      "Epoch 97/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.4020 - accuracy: 0.9754 - recall_m: 0.4776 - precision_m: 0.5106\n",
      "Epoch 98/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3950 - accuracy: 0.9744 - recall_m: 0.6269 - precision_m: 0.4922\n",
      "Epoch 99/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3890 - accuracy: 0.9784 - recall_m: 0.4627 - precision_m: 0.5886\n",
      "Epoch 100/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3845 - accuracy: 0.9709 - recall_m: 0.6667 - precision_m: 0.4467\n",
      "Epoch 101/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3808 - accuracy: 0.9786 - recall_m: 0.2189 - precision_m: 0.7586\n",
      "Epoch 102/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3780 - accuracy: 0.9639 - recall_m: 0.7761 - precision_m: 0.3900\n",
      "Epoch 103/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3721 - accuracy: 0.9770 - recall_m: 0.1194 - precision_m: 0.7742\n",
      "Epoch 104/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3653 - accuracy: 0.9688 - recall_m: 0.8259 - precision_m: 0.4357\n",
      "Epoch 105/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3575 - accuracy: 0.9751 - recall_m: 0.5124 - precision_m: 0.5049\n",
      "Epoch 106/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3555 - accuracy: 0.9775 - recall_m: 0.1294 - precision_m: 0.8387\n",
      "Epoch 107/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3469 - accuracy: 0.9751 - recall_m: 0.4080 - precision_m: 0.5062\n",
      "Epoch 108/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3432 - accuracy: 0.9691 - recall_m: 0.6716 - precision_m: 0.4272\n",
      "Epoch 109/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3367 - accuracy: 0.9760 - recall_m: 0.4030 - precision_m: 0.5294\n",
      "Epoch 110/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.3311 - accuracy: 0.9781 - recall_m: 0.3632 - precision_m: 0.6083\n",
      "Epoch 111/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3267 - accuracy: 0.9751 - recall_m: 0.4378 - precision_m: 0.5057\n",
      "Epoch 112/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3214 - accuracy: 0.9766 - recall_m: 0.5274 - precision_m: 0.5354\n",
      "Epoch 113/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3172 - accuracy: 0.9734 - recall_m: 0.4826 - precision_m: 0.4709\n",
      "Epoch 114/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3120 - accuracy: 0.9784 - recall_m: 0.4279 - precision_m: 0.5972\n",
      "Epoch 115/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.3068 - accuracy: 0.9789 - recall_m: 0.4179 - precision_m: 0.6176\n",
      "Epoch 116/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.9754 - recall_m: 0.4826 - precision_m: 0.5105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2978 - accuracy: 0.9775 - recall_m: 0.5522 - precision_m: 0.5522\n",
      "Epoch 118/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2947 - accuracy: 0.9772 - recall_m: 0.4826 - precision_m: 0.5543\n",
      "Epoch 119/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2900 - accuracy: 0.9794 - recall_m: 0.3483 - precision_m: 0.6731\n",
      "Epoch 120/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2858 - accuracy: 0.9779 - recall_m: 0.3682 - precision_m: 0.5968\n",
      "Epoch 121/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2813 - accuracy: 0.9780 - recall_m: 0.5025 - precision_m: 0.5706\n",
      "Epoch 122/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2775 - accuracy: 0.9776 - recall_m: 0.4229 - precision_m: 0.5743\n",
      "Epoch 123/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2743 - accuracy: 0.9789 - recall_m: 0.3632 - precision_m: 0.6404\n",
      "Epoch 124/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2688 - accuracy: 0.9790 - recall_m: 0.4577 - precision_m: 0.6093\n",
      "Epoch 125/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2643 - accuracy: 0.9795 - recall_m: 0.5970 - precision_m: 0.5911\n",
      "Epoch 126/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2609 - accuracy: 0.9793 - recall_m: 0.3881 - precision_m: 0.6446\n",
      "Epoch 127/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.2570 - accuracy: 0.9819 - recall_m: 0.5174 - precision_m: 0.6842\n",
      "Epoch 128/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2542 - accuracy: 0.9775 - recall_m: 0.6119 - precision_m: 0.5467\n",
      "Epoch 129/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2514 - accuracy: 0.9810 - recall_m: 0.3333 - precision_m: 0.7882\n",
      "Epoch 130/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2461 - accuracy: 0.9806 - recall_m: 0.4925 - precision_m: 0.6513\n",
      "Epoch 131/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2441 - accuracy: 0.9769 - recall_m: 0.6318 - precision_m: 0.5336\n",
      "Epoch 132/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2419 - accuracy: 0.9797 - recall_m: 0.2289 - precision_m: 0.8679\n",
      "Epoch 133/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2358 - accuracy: 0.9789 - recall_m: 0.5672 - precision_m: 0.5816\n",
      "Epoch 134/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2328 - accuracy: 0.9796 - recall_m: 0.5821 - precision_m: 0.5969\n",
      "Epoch 135/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2312 - accuracy: 0.9824 - recall_m: 0.3284 - precision_m: 0.9167\n",
      "Epoch 136/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2288 - accuracy: 0.9746 - recall_m: 0.6866 - precision_m: 0.4964\n",
      "Epoch 137/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2225 - accuracy: 0.9835 - recall_m: 0.4577 - precision_m: 0.8000\n",
      "Epoch 138/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2202 - accuracy: 0.9836 - recall_m: 0.4925 - precision_m: 0.7734\n",
      "Epoch 139/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2179 - accuracy: 0.9796 - recall_m: 0.6517 - precision_m: 0.5848\n",
      "Epoch 140/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2141 - accuracy: 0.9819 - recall_m: 0.3582 - precision_m: 0.8182\n",
      "Epoch 141/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2096 - accuracy: 0.9851 - recall_m: 0.5522 - precision_m: 0.7929\n",
      "Epoch 142/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2098 - accuracy: 0.9780 - recall_m: 0.6119 - precision_m: 0.5566\n",
      "Epoch 143/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.2056 - accuracy: 0.9834 - recall_m: 0.3930 - precision_m: 0.8778\n",
      "Epoch 144/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.2026 - accuracy: 0.9809 - recall_m: 0.6866 - precision_m: 0.6053\n",
      "Epoch 145/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1999 - accuracy: 0.9820 - recall_m: 0.5622 - precision_m: 0.6686\n",
      "Epoch 146/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1983 - accuracy: 0.9830 - recall_m: 0.3731 - precision_m: 0.8824\n",
      "Epoch 147/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1949 - accuracy: 0.9818 - recall_m: 0.6368 - precision_m: 0.6368\n",
      "Epoch 148/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1905 - accuracy: 0.9849 - recall_m: 0.5970 - precision_m: 0.7500\n",
      "Epoch 149/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1881 - accuracy: 0.9840 - recall_m: 0.4229 - precision_m: 0.8763\n",
      "Epoch 150/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1858 - accuracy: 0.9820 - recall_m: 0.5821 - precision_m: 0.6610\n",
      "Epoch 151/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1815 - accuracy: 0.9855 - recall_m: 0.6318 - precision_m: 0.7515\n",
      "Epoch 152/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1796 - accuracy: 0.9852 - recall_m: 0.5672 - precision_m: 0.7862\n",
      "Epoch 153/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1764 - accuracy: 0.9846 - recall_m: 0.7065 - precision_m: 0.6893\n",
      "Epoch 154/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1739 - accuracy: 0.9876 - recall_m: 0.7065 - precision_m: 0.7802\n",
      "Epoch 155/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1728 - accuracy: 0.9852 - recall_m: 0.5970 - precision_m: 0.7643\n",
      "Epoch 156/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1804 - accuracy: 0.9779 - recall_m: 0.8109 - precision_m: 0.5397\n",
      "Epoch 157/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1740 - accuracy: 0.9833 - recall_m: 0.4179 - precision_m: 0.8317\n",
      "Epoch 158/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1719 - accuracy: 0.9836 - recall_m: 0.5522 - precision_m: 0.7303\n",
      "Epoch 159/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1661 - accuracy: 0.9816 - recall_m: 0.5622 - precision_m: 0.6570\n",
      "Epoch 160/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1645 - accuracy: 0.9825 - recall_m: 0.5871 - precision_m: 0.6743\n",
      "Epoch 161/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1629 - accuracy: 0.9839 - recall_m: 0.5075 - precision_m: 0.7727\n",
      "Epoch 162/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1585 - accuracy: 0.9843 - recall_m: 0.5124 - precision_m: 0.7863\n",
      "Epoch 163/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1592 - accuracy: 0.9818 - recall_m: 0.6318 - precision_m: 0.6382\n",
      "Epoch 164/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1520 - accuracy: 0.9881 - recall_m: 0.6368 - precision_m: 0.8533\n",
      "Epoch 165/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1512 - accuracy: 0.9869 - recall_m: 0.6716 - precision_m: 0.7759\n",
      "Epoch 166/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1508 - accuracy: 0.9854 - recall_m: 0.6915 - precision_m: 0.7165\n",
      "Epoch 167/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1451 - accuracy: 0.9869 - recall_m: 0.6766 - precision_m: 0.7727\n",
      "Epoch 168/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1477 - accuracy: 0.9868 - recall_m: 0.6915 - precision_m: 0.7596\n",
      "Epoch 169/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1650 - accuracy: 0.9758 - recall_m: 0.9055 - precision_m: 0.5098\n",
      "Epoch 170/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1554 - accuracy: 0.9809 - recall_m: 0.4577 - precision_m: 0.6765\n",
      "Epoch 171/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1645 - accuracy: 0.9766 - recall_m: 0.1642 - precision_m: 0.6346\n",
      "Epoch 172/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1627 - accuracy: 0.9795 - recall_m: 0.3085 - precision_m: 0.7126\n",
      "Epoch 173/1000\n",
      "32/32 [==============================] - 0s 11ms/step - loss: 0.1623 - accuracy: 0.9799 - recall_m: 0.6269 - precision_m: 0.5943\n",
      "Epoch 174/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1503 - accuracy: 0.9787 - recall_m: 0.6468 - precision_m: 0.5677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1460 - accuracy: 0.9797 - recall_m: 0.4478 - precision_m: 0.6383\n",
      "Epoch 176/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1513 - accuracy: 0.9786 - recall_m: 0.2388 - precision_m: 0.7273\n",
      "Epoch 177/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1459 - accuracy: 0.9797 - recall_m: 0.2537 - precision_m: 0.8095\n",
      "Epoch 178/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1410 - accuracy: 0.9808 - recall_m: 0.4279 - precision_m: 0.6880\n",
      "Epoch 179/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1389 - accuracy: 0.9769 - recall_m: 0.5871 - precision_m: 0.5364\n",
      "Epoch 180/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1380 - accuracy: 0.9785 - recall_m: 0.6368 - precision_m: 0.5639\n",
      "Epoch 181/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1399 - accuracy: 0.9775 - recall_m: 0.4677 - precision_m: 0.5629\n",
      "Epoch 182/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1400 - accuracy: 0.9786 - recall_m: 0.4080 - precision_m: 0.6119\n",
      "Epoch 183/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1353 - accuracy: 0.9814 - recall_m: 0.4478 - precision_m: 0.7031\n",
      "Epoch 184/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1315 - accuracy: 0.9818 - recall_m: 0.4876 - precision_m: 0.6950\n",
      "Epoch 185/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1282 - accuracy: 0.9818 - recall_m: 0.6567 - precision_m: 0.6316\n",
      "Epoch 186/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1279 - accuracy: 0.9812 - recall_m: 0.6816 - precision_m: 0.6143\n",
      "Epoch 187/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1248 - accuracy: 0.9830 - recall_m: 0.4577 - precision_m: 0.7731\n",
      "Epoch 188/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1260 - accuracy: 0.9826 - recall_m: 0.3333 - precision_m: 0.9306\n",
      "Epoch 189/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1236 - accuracy: 0.9836 - recall_m: 0.3881 - precision_m: 0.9070\n",
      "Epoch 190/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1196 - accuracy: 0.9846 - recall_m: 0.5124 - precision_m: 0.8047\n",
      "Epoch 191/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1193 - accuracy: 0.9831 - recall_m: 0.6318 - precision_m: 0.6755\n",
      "Epoch 192/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1175 - accuracy: 0.9846 - recall_m: 0.6468 - precision_m: 0.7143\n",
      "Epoch 193/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1161 - accuracy: 0.9845 - recall_m: 0.5025 - precision_m: 0.8080\n",
      "Epoch 194/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1139 - accuracy: 0.9860 - recall_m: 0.5522 - precision_m: 0.8346\n",
      "Epoch 195/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1125 - accuracy: 0.9859 - recall_m: 0.5920 - precision_m: 0.7933\n",
      "Epoch 196/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1109 - accuracy: 0.9870 - recall_m: 0.7065 - precision_m: 0.7594\n",
      "Epoch 197/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1091 - accuracy: 0.9868 - recall_m: 0.6667 - precision_m: 0.7746\n",
      "Epoch 198/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1081 - accuracy: 0.9876 - recall_m: 0.6020 - precision_m: 0.8643\n",
      "Epoch 199/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1070 - accuracy: 0.9861 - recall_m: 0.6269 - precision_m: 0.7778\n",
      "Epoch 200/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1035 - accuracy: 0.9891 - recall_m: 0.6766 - precision_m: 0.8608\n",
      "Epoch 201/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1028 - accuracy: 0.9886 - recall_m: 0.6866 - precision_m: 0.8313\n",
      "Epoch 202/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1006 - accuracy: 0.9874 - recall_m: 0.6567 - precision_m: 0.8049\n",
      "Epoch 203/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0996 - accuracy: 0.9886 - recall_m: 0.6915 - precision_m: 0.8274\n",
      "Epoch 204/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0981 - accuracy: 0.9898 - recall_m: 0.7512 - precision_m: 0.8251\n",
      "Epoch 205/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0980 - accuracy: 0.9883 - recall_m: 0.6617 - precision_m: 0.8365\n",
      "Epoch 206/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0959 - accuracy: 0.9883 - recall_m: 0.6468 - precision_m: 0.8497\n",
      "Epoch 207/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0956 - accuracy: 0.9886 - recall_m: 0.6567 - precision_m: 0.8571\n",
      "Epoch 208/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0932 - accuracy: 0.9901 - recall_m: 0.7065 - precision_m: 0.8765\n",
      "Epoch 209/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0919 - accuracy: 0.9900 - recall_m: 0.7612 - precision_m: 0.8270\n",
      "Epoch 210/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0916 - accuracy: 0.9901 - recall_m: 0.7015 - precision_m: 0.8813\n",
      "Epoch 211/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0892 - accuracy: 0.9905 - recall_m: 0.6915 - precision_m: 0.9085\n",
      "Epoch 212/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0886 - accuracy: 0.9902 - recall_m: 0.8060 - precision_m: 0.8060\n",
      "Epoch 213/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0852 - accuracy: 0.9918 - recall_m: 0.7164 - precision_m: 0.9412\n",
      "Epoch 214/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0854 - accuracy: 0.9914 - recall_m: 0.7313 - precision_m: 0.9074\n",
      "Epoch 215/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0832 - accuracy: 0.9919 - recall_m: 0.8159 - precision_m: 0.8542\n",
      "Epoch 216/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0856 - accuracy: 0.9900 - recall_m: 0.6816 - precision_m: 0.8954\n",
      "Epoch 217/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1159 - accuracy: 0.9758 - recall_m: 0.9801 - precision_m: 0.5090\n",
      "Epoch 218/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1094 - accuracy: 0.9781 - recall_m: 0.4229 - precision_m: 0.5903\n",
      "Epoch 219/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1232 - accuracy: 0.9759 - recall_m: 0.2935 - precision_m: 0.5364\n",
      "Epoch 220/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1329 - accuracy: 0.9751 - recall_m: 0.2488 - precision_m: 0.5102\n",
      "Epoch 221/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1158 - accuracy: 0.9783 - recall_m: 0.2388 - precision_m: 0.6957\n",
      "Epoch 222/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1114 - accuracy: 0.9805 - recall_m: 0.3184 - precision_m: 0.7711\n",
      "Epoch 223/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1126 - accuracy: 0.9765 - recall_m: 0.4030 - precision_m: 0.5436\n",
      "Epoch 224/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1183 - accuracy: 0.9731 - recall_m: 0.3930 - precision_m: 0.4593\n",
      "Epoch 225/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1130 - accuracy: 0.9762 - recall_m: 0.3682 - precision_m: 0.5401\n",
      "Epoch 226/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1094 - accuracy: 0.9761 - recall_m: 0.2736 - precision_m: 0.5500\n",
      "Epoch 227/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1064 - accuracy: 0.9789 - recall_m: 0.2637 - precision_m: 0.7162\n",
      "Epoch 228/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1056 - accuracy: 0.9791 - recall_m: 0.2537 - precision_m: 0.7500\n",
      "Epoch 229/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1015 - accuracy: 0.9783 - recall_m: 0.2985 - precision_m: 0.6452\n",
      "Epoch 230/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1029 - accuracy: 0.9747 - recall_m: 0.4179 - precision_m: 0.4970\n",
      "Epoch 231/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0993 - accuracy: 0.9776 - recall_m: 0.5224 - precision_m: 0.5585\n",
      "Epoch 232/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0985 - accuracy: 0.9764 - recall_m: 0.4179 - precision_m: 0.5385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0981 - accuracy: 0.9775 - recall_m: 0.2935 - precision_m: 0.6082\n",
      "Epoch 234/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0991 - accuracy: 0.9778 - recall_m: 0.2537 - precision_m: 0.6456\n",
      "Epoch 235/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.0966 - accuracy: 0.9779 - recall_m: 0.2438 - precision_m: 0.6622\n",
      "Epoch 236/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0929 - accuracy: 0.9794 - recall_m: 0.3333 - precision_m: 0.6837\n",
      "Epoch 237/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0915 - accuracy: 0.9796 - recall_m: 0.5373 - precision_m: 0.6067\n",
      "Epoch 238/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0931 - accuracy: 0.9768 - recall_m: 0.5522 - precision_m: 0.5362\n",
      "Epoch 239/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0924 - accuracy: 0.9775 - recall_m: 0.4279 - precision_m: 0.5695\n",
      "Epoch 240/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0910 - accuracy: 0.9789 - recall_m: 0.2935 - precision_m: 0.6860\n",
      "Epoch 241/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0893 - accuracy: 0.9801 - recall_m: 0.2786 - precision_m: 0.8000\n",
      "Epoch 242/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0873 - accuracy: 0.9810 - recall_m: 0.3781 - precision_m: 0.7379\n",
      "Epoch 243/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0859 - accuracy: 0.9835 - recall_m: 0.5522 - precision_m: 0.7255\n",
      "Epoch 244/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0872 - accuracy: 0.9781 - recall_m: 0.6070 - precision_m: 0.5596\n",
      "Epoch 245/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0837 - accuracy: 0.9816 - recall_m: 0.5373 - precision_m: 0.6667\n",
      "Epoch 246/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 0.9820 - recall_m: 0.3930 - precision_m: 0.7822\n",
      "Epoch 247/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0816 - accuracy: 0.9830 - recall_m: 0.3532 - precision_m: 0.9221\n",
      "Epoch 248/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0798 - accuracy: 0.9836 - recall_m: 0.4726 - precision_m: 0.7917\n",
      "Epoch 249/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0793 - accuracy: 0.9821 - recall_m: 0.6119 - precision_m: 0.6543\n",
      "Epoch 250/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0790 - accuracy: 0.9826 - recall_m: 0.6119 - precision_m: 0.6685\n",
      "Epoch 251/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0760 - accuracy: 0.9852 - recall_m: 0.5970 - precision_m: 0.7643\n",
      "Epoch 252/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0772 - accuracy: 0.9835 - recall_m: 0.4229 - precision_m: 0.8416\n",
      "Epoch 253/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0743 - accuracy: 0.9868 - recall_m: 0.5323 - precision_m: 0.8992\n",
      "Epoch 254/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0751 - accuracy: 0.9837 - recall_m: 0.6766 - precision_m: 0.6766\n",
      "Epoch 255/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0729 - accuracy: 0.9852 - recall_m: 0.5871 - precision_m: 0.7712\n",
      "Epoch 256/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0702 - accuracy: 0.9876 - recall_m: 0.5920 - precision_m: 0.8750\n",
      "Epoch 257/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0690 - accuracy: 0.9885 - recall_m: 0.6468 - precision_m: 0.8609\n",
      "Epoch 258/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0695 - accuracy: 0.9877 - recall_m: 0.6816 - precision_m: 0.8012\n",
      "Epoch 259/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0699 - accuracy: 0.9860 - recall_m: 0.6716 - precision_m: 0.7459\n",
      "Epoch 260/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0687 - accuracy: 0.9877 - recall_m: 0.5871 - precision_m: 0.8872\n",
      "Epoch 261/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0663 - accuracy: 0.9886 - recall_m: 0.6866 - precision_m: 0.8313\n",
      "Epoch 262/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0657 - accuracy: 0.9887 - recall_m: 0.7463 - precision_m: 0.7937\n",
      "Epoch 263/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0661 - accuracy: 0.9881 - recall_m: 0.6517 - precision_m: 0.8397\n",
      "Epoch 264/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0642 - accuracy: 0.9887 - recall_m: 0.6219 - precision_m: 0.8993\n",
      "Epoch 265/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0649 - accuracy: 0.9875 - recall_m: 0.7313 - precision_m: 0.7617\n",
      "Epoch 266/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0633 - accuracy: 0.9887 - recall_m: 0.6915 - precision_m: 0.8323\n",
      "Epoch 267/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0633 - accuracy: 0.9895 - recall_m: 0.6219 - precision_m: 0.9398\n",
      "Epoch 268/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0619 - accuracy: 0.9893 - recall_m: 0.7612 - precision_m: 0.8010\n",
      "Epoch 269/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0602 - accuracy: 0.9914 - recall_m: 0.7214 - precision_m: 0.9177\n",
      "Epoch 270/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0600 - accuracy: 0.9908 - recall_m: 0.6816 - precision_m: 0.9320\n",
      "Epoch 271/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0597 - accuracy: 0.9900 - recall_m: 0.7811 - precision_m: 0.8135\n",
      "Epoch 272/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0688 - accuracy: 0.9860 - recall_m: 0.5821 - precision_m: 0.8069\n",
      "Epoch 273/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1252 - accuracy: 0.9655 - recall_m: 0.9950 - precision_m: 0.4211\n",
      "Epoch 274/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.0941 - accuracy: 0.9705 - recall_m: 0.5124 - precision_m: 0.4274\n",
      "Epoch 275/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1080 - accuracy: 0.9732 - recall_m: 0.1045 - precision_m: 0.3818\n",
      "Epoch 276/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1172 - accuracy: 0.9744 - recall_m: 0.0348 - precision_m: 0.3889\n",
      "Epoch 277/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1184 - accuracy: 0.9746 - recall_m: 0.0000e+00 - precision_m: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "32/32 [==============================] - 0s 10ms/step - loss: 0.1159 - accuracy: 0.9750 - recall_m: 0.0050 - precision_m: 1.0000\n",
      "Epoch 279/1000\n",
      "32/32 [==============================] - 0s 9ms/step - loss: 0.1079 - accuracy: 0.9755 - recall_m: 0.0448 - precision_m: 0.6923\n",
      "Epoch 280/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1011 - accuracy: 0.9728 - recall_m: 0.1343 - precision_m: 0.3803\n",
      "Epoch 281/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1014 - accuracy: 0.9736 - recall_m: 0.3134 - precision_m: 0.4632\n",
      "Epoch 282/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.1026 - accuracy: 0.9737 - recall_m: 0.4030 - precision_m: 0.4737\n",
      "Epoch 283/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0971 - accuracy: 0.9740 - recall_m: 0.3831 - precision_m: 0.4783\n",
      "Epoch 284/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0919 - accuracy: 0.9750 - recall_m: 0.2985 - precision_m: 0.5042\n",
      "Epoch 285/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0882 - accuracy: 0.9764 - recall_m: 0.2935 - precision_m: 0.5566\n",
      "Epoch 286/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0859 - accuracy: 0.9770 - recall_m: 0.2587 - precision_m: 0.5977\n",
      "Epoch 287/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0791 - accuracy: 0.9786 - recall_m: 0.3184 - precision_m: 0.6531\n",
      "Epoch 288/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0742 - accuracy: 0.9799 - recall_m: 0.4229 - precision_m: 0.6538\n",
      "Epoch 289/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0729 - accuracy: 0.9814 - recall_m: 0.5672 - precision_m: 0.6477\n",
      "Epoch 290/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0724 - accuracy: 0.9816 - recall_m: 0.6468 - precision_m: 0.6311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0704 - accuracy: 0.9816 - recall_m: 0.6070 - precision_m: 0.6421\n",
      "Epoch 292/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0667 - accuracy: 0.9851 - recall_m: 0.5572 - precision_m: 0.7887\n",
      "Epoch 293/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0699 - accuracy: 0.9822 - recall_m: 0.4229 - precision_m: 0.7658\n",
      "Epoch 294/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0706 - accuracy: 0.9811 - recall_m: 0.3930 - precision_m: 0.7315\n",
      "Epoch 295/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0709 - accuracy: 0.9818 - recall_m: 0.4677 - precision_m: 0.7068\n",
      "Epoch 296/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0686 - accuracy: 0.9814 - recall_m: 0.5771 - precision_m: 0.6444\n",
      "Epoch 297/1000\n",
      "32/32 [==============================] - 0s 8ms/step - loss: 0.0669 - accuracy: 0.9840 - recall_m: 0.6915 - precision_m: 0.6780\n",
      "Epoch 298/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-63ed8590dafe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x, y_end, batch_size=x.shape[0], epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_end.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN использовать можно и даже немного нужно\n",
    "А вот seq2seq не надо - у вас же одинаковая длина входа и выхода. Имплементация будет очень похожа не языковую модельку, как была в последней домашке.\n",
    "\n",
    "Если это исследования, а не в прод катить, я бы попробовал LMU и LSTM-SHA из реккурентных и Sparse Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_chunks(size):\n",
    "    return (size // CHUNK_TIME - 1) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a774be3b49af4e699fd5fecdbb1a6050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f776c953f804cd9a3d848fbdef62526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1295c9afb245f890dc84644ab4936b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15476a89d0f46709425358a589bd858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    for train_files, val_files in tqdm_notebook(list(zip(iterate_files(train_df), iterate_files(val_df)))):\n",
    "        train_data, train_events = get_data_multiple(train_df, train_files)\n",
    "        train_generator = iterate_chunks(train_data, train_events)\n",
    "\n",
    "        val_data, val_events = get_data_multiple(val_df, val_files)\n",
    "        val_generator = iterate_chunks(val_data, val_events)\n",
    "\n",
    "        model.fit_generator(\n",
    "            train_generator, \n",
    "            epochs=1, \n",
    "            steps_per_epoch=number_of_chunks(train_events[0].shape[0]),\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=number_of_chunks(val_events[0].shape[0]) // 10\n",
    "        )                \n",
    "        model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, train_events = get_data_multiple(train_df, train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Участки с нулевым precision/recall - почему val и train одинаково содержат/не содержат нули? - удалены временно\n",
    "- Высокий precision/recall на валидации не соответствует действительности - проверить!!!!\n",
    "- Влияет ли присутствие одинаковых пациентов/сессий в train/test? - проверить!!!!\n",
    "- Резко падает precision/recall - какие участки дают такой эффект?\n",
    "\n",
    "\n",
    "- Файлы во всю длину, не учитывать loss \n",
    "- Собирать чанки tN файлов в один файл\n",
    "- Переименовывать каналы других интерфейсов\n",
    "- Влияние масштабирования сигнала?\n",
    "\n",
    "\n",
    "- Можно ли использовать чанку большего размера? Можно ли ее предварительно сжать с помощью CNN? Как это повлияет на предсказание?\n",
    "\n",
    "- Применима ли к данным фильтрация? Шум сети/моргания-движения/?\n",
    "- Имеет ли смысл скалировать данные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1739,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = next(iterate_files(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1740,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_events = get_data_multiple(val_df, val_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предыдущая чанка содержит не нули и единицы, а вероятности. Может быть, добавить пороги?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1717,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df4ea402d72401390a5292fb570dd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "\n",
    "previous_state = np.zeros((BATCH_SIZE, CHUNK_TIME, 1))\n",
    "\n",
    "predicted_states = []\n",
    "true_states = []\n",
    "\n",
    "for (d, _), true_state in tqdm_notebook(iterate_chunks(test_data, test_events)):\n",
    "    current_state = model.predict([d, previous_state])\n",
    "    predicted_states.append(current_state)\n",
    "    true_states.append(true_state)\n",
    "    previous_state = current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_states = np.hstack(true_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 762500, 1)"
      ]
     },
     "execution_count": 1719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_true_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1720,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_states = np.hstack(predicted_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 762500, 1)"
      ]
     },
     "execution_count": 1721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predicted_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16694266393442622"
      ]
     },
     "execution_count": 1722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_true_states > 0.5).sum() / (all_true_states > -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nonzero_index, row in enumerate(all_true_states):\n",
    "    if row.max() > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1724,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.squeeze(all_predicted_states[nonzero_index])\n",
    "true = np.squeeze(all_true_states[nonzero_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1725,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007317321"
      ]
     },
     "execution_count": 1727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[true > 0.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0073153907"
      ]
     },
     "execution_count": 1728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[true < 0.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f71ff42a710>"
      ]
     },
     "execution_count": 1726,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(pred[true > 0.5], label=\"True\")\n",
    "sns.distplot(pred[true < 0.5], label=\"False\")\n",
    "plt.legend()\n",
    "# plt.xlim(0, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare focal loss params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_focal_loss(y_true, y_pred, gamma, alpha):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    p1 = y_pred[(y_true > 0.5)]\n",
    "    p0 = y_pred[(y_true < 0.5)]\n",
    "    p1_mean = - np.sum(alpha * ((1 - p1) ** gamma) * np.log(p1))\n",
    "    p0_mean = - np.sum((1 - alpha) * (p0 ** gamma) * np.log(1 - p0))\n",
    "    return (p1_mean + p0_mean) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 1000\n",
    "y_true = (np.random.rand(shape) < 0.3).astype(float)\n",
    "y_pred_1 = 0.5 * np.ones(y_true.shape)\n",
    "y_pred_2 = 0.1 * np.ones(y_true.shape) # Should be greater than 1\n",
    "y_pred_3 = 0.49 * np.ones(y_true.shape) + (y_true > 0.5) * (0.9 - 0.49) # Should be less than 1\n",
    "y_pred_4 = 0.99 * np.ones(y_true.shape) # Should be greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17328679513998635"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_focal_loss(y_true, y_pred_1, gamma=gamma, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3279382440610576"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_focal_loss(y_true, y_pred_2, gamma=gamma, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11498288055263572"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_focal_loss(y_true, y_pred_3, gamma=gamma, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5660729280736512"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_focal_loss(y_true, y_pred_4, gamma=gamma, alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare small MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = iterate_chunks(data, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(generator)\n",
    "x, y = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100), solver=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = (np.squeeze(y).mean(axis=1) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y.sum() / new_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = x.reshape(32, 250 * 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 100, 100, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(new_x, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(new_x, new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = eeg_input\n",
    "\n",
    "for cnn_filters in CNN_FILTERS:\n",
    "    feature_extractor = keras.layers.Conv1D(cnn_filters, kernel_size=3, padding=\"same\", activation=\"relu\")(feature_extractor)\n",
    "    feature_extractor = keras.layers.Conv1D(cnn_filters, kernel_size=3, padding=\"same\", activation=\"relu\")(feature_extractor)\n",
    "    feature_extractor = keras.layers.MaxPool1D(pool_size=2, padding=\"same\")(feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, encoder_h_state, encoder_c_state = keras.layers.LSTM(RNN_SIZE, stateful=True, return_state=True)(feature_extractor)\n",
    "\n",
    "events_input = keras.layers.Input(batch_shape=(BATCH_SIZE, CHUNK_TIME, 1), name=\"events\")\n",
    "\n",
    "decoder_outputs, _, _ = keras.layers.LSTM(RNN_SIZE, return_sequences=True, return_state=True)(\n",
    "    events_input, \n",
    "    initial_state=[encoder_h_state, encoder_c_state]\n",
    ")\n",
    "decoder_outputs = keras.layers.Dense(1, activation='sigmoid')(decoder_outputs)\n",
    "\n",
    "model = keras.models.Model(inputs=[eeg_input, events_input], outputs=[decoder_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.layers import Dense,Activation,Dropout\n",
    "# from keras.layers import LSTM,Bidirectional #could try TimeDistributed(Dense(...))\n",
    "# from keras.models import Sequential, load_model\n",
    "# from keras import optimizers,regularizers\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32,W_regularizer=regularizers.l2(l=0.01), batch_input_shape=(BATCH_SIZE, CHUNK_TIME // 2, len(CHANNELS))))\n",
    "# model.add(Bidirectional(LSTM(32, return_sequences=True, stateful=True)))#, input_shape=(seqlength, features)) ) ### bidirectional ---><---\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(64, activation='relu',W_regularizer=regularizers.l2(l=0.01)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def focal_loss(gamma=0, alpha=0.5):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#         total_sum = - K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \n",
    "#         total_sum -= K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "#         return 2 * total_sum / tf.cast(K.size(y_true), dtype=tf.float32)\n",
    "#     return focal_loss_fixed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
