{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tensorflow dataset\n",
    "- Simple LSTM Network\n",
    "- Long sequences to short chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/24/0cdbf8907e1e3bc5a8da03345c23cbed7044330bb8f73bb12e711a640a00/pandas-0.24.2-cp35-cp35m-manylinux1_x86_64.whl (10.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.0MB 223kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas) (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.5/dist-packages (from pandas) (1.16.1)\n",
      "Collecting pytz>=2011k (from pandas)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/f9/f0b53f88060247251bf481fa6ea62cd0d25bf1b11a87888e53ce5b7c8ad2/pytz-2019.3-py2.py3-none-any.whl (509kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 168kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.5/dist-packages (from python-dateutil>=2.5.0->pandas) (1.12.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-0.24.2 pytz-2019.3\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mne\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/af/9c64ac8f75b1c932ca5fb16bc27740cd9b9817f9173a6608ae999e82bb6a/mne-0.20.0-py3-none-any.whl (6.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.6MB 841kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.5/dist-packages (from mne) (1.16.1)\n",
      "Collecting scipy>=0.17.1 (from mne)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/60/8cbf00c0deb50a971e6e3a015fb32513960a92867df979870a454481817c/scipy-1.4.1-cp35-cp35m-manylinux1_x86_64.whl (26.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.0MB 592kB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: scipy, mne\n",
      "Successfully installed mne-0.20.0 scipy-1.4.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/ec/32310181e803f5d22e0dd33eb18924489b2f8d08cf5b6e116a93a6a5d1c6/scikit_learn-0.22.2.post1-cp35-cp35m-manylinux1_x86_64.whl (7.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.0MB 1.9MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.5/dist-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.5/dist-packages (from scikit-learn) (1.16.1)\n",
      "Collecting joblib>=0.11 (from scikit-learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/5c/cf6a2b65a321c4a209efcdf64c2689efae2cb62661f8f6f4bb28547cf1bf/joblib-0.14.1-py2.py3-none-any.whl (294kB)\n",
      "\u001b[K    100% |████████████████████████████████| 296kB 3.3MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: joblib, scikit-learn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.2.post1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/86/43b8c9138ef4c2a1c492fee92792c83c13799d0e2061ff810d3826d06cd1/seaborn-0.9.1-py2.py3-none-any.whl (216kB)\n",
      "\u001b[K    100% |████████████████████████████████| 225kB 3.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.5/dist-packages (from seaborn) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.5/dist-packages (from seaborn) (1.16.1)\n",
      "Requirement already satisfied: matplotlib>=1.5.3 in /usr/local/lib/python3.5/dist-packages (from seaborn) (3.0.2)\n",
      "Requirement already satisfied: scipy>=0.17.1 in /usr/local/lib/python3.5/dist-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.5/dist-packages (from pandas>=0.17.1->seaborn) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.5/dist-packages (from pandas>=0.17.1->seaborn) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.5.3->seaborn) (2.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.5.3->seaborn) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.5/dist-packages (from matplotlib>=1.5.3->seaborn) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.5/dist-packages (from python-dateutil>=2.5.0->pandas>=0.17.1->seaborn) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.5/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.5.3->seaborn) (40.8.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.9.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.5/dist-packages (from keras) (1.16.1)\n",
      "Collecting pyyaml (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
      "\u001b[K    100% |████████████████████████████████| 276kB 390kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.5/dist-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.5/dist-packages (from keras) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.5/dist-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.5/dist-packages (from keras) (1.0.7)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: pyyaml, keras\n",
      "Successfully installed keras-2.3.1 pyyaml-5.3.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4a/1c/6359be64e8301b84160f6f6f7936bbfaaa5e9a4eab6cbc681db07600b949/tqdm-4.45.0-py2.py3-none-any.whl (60kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 698kB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.45.0\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какие каналы содержат "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:\n",
    "- Один сэмпл содержит чанк сигнала, чанки не пересекаются\n",
    "- Считывание происходит из случайных файлов из списка\n",
    "- Чанки рандомизированы:\n",
    "    - Учесть рандомизацию по номеру пациента, сессии, времени"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = [\"file\", \"start\", \"end\", \"label\", \"confidence\"]\n",
    "train_df = pd.read_csv(\"../_DOCS/ref_train.txt\", sep=\" \", names=header)\n",
    "val_df = pd.read_csv(\"../_DOCS/ref_dev.txt\", sep=\" \", names=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_file(full_file):\n",
    "    parts = full_file.split(\"_\")\n",
    "    patient = int(parts[0])\n",
    "    session = int(parts[1][1:])\n",
    "    file = int(parts[2][1:])\n",
    "    return [patient, session, file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[258, 2, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_file(\"00000258_s002_t000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_file_info(df):\n",
    "    values = np.array(df[\"file\"].apply(preprocess_file).tolist())\n",
    "    files_df = pd.DataFrame(values, columns=[\"patient\", \"session\", \"chunk\"], index=df.index)\n",
    "    return df.merge(files_df, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = append_file_info(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = append_file_info(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO add other electrode formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_files(df, dataset):\n",
    "    paths = {}\n",
    "\n",
    "    for root, dirs, files in os.walk(\"../edf/{}\".format(dataset)):\n",
    "        path = root.split(os.sep)\n",
    "        for file in files:\n",
    "            if \".edf\" in file:\n",
    "                name = file.split(\".\")[0]\n",
    "                paths[name] = os.path.abspath(root) + \"/\" +  file\n",
    "    \n",
    "    df[\"full_path\"] = df[\"file\"].apply(paths.get)\n",
    "    return df[df[\"full_path\"].apply(lambda x: \"01_tcp_ar\" in str(x))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = attach_files(train_df, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = attach_files(val_df, \"dev\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove bckg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bckg_files(df):\n",
    "    files_with_seizures = df[df[\"label\"] == \"seiz\"][\"file\"].unique()\n",
    "    return df[df[\"file\"].isin(files_with_seizures)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = remove_bckg_files(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = remove_bckg_files(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate channels intersection and proper sample rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edf_info(df):\n",
    "    files = df[\"full_path\"].unique()\n",
    "\n",
    "    edf_data = []\n",
    "\n",
    "    for file in tqdm_notebook(files):\n",
    "        edf = mne.io.read_raw_edf(file, verbose=\"ERROR\")\n",
    "        data = {\n",
    "            field: edf.info[field]\n",
    "            for field in [\"ch_names\", \"sfreq\"]\n",
    "        }\n",
    "        edf_data.append(data)\n",
    "        \n",
    "    return pd.DataFrame(edf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07804b40fd34b0db398ac212310d34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=458.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_edf_df = get_edf_info(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "203a3c72366e4e9db2aee7e23fc58113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=241.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_edf_df = get_edf_info(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_FREQUENCY = int(min(train_edf_df[\"sfreq\"].min(), val_edf_df[\"sfreq\"].min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter([\n",
    "    channel for channels_list in train_edf_df[\"ch_names\"] for channel in channels_list\n",
    "] + [\n",
    "    channel for channels_list in val_edf_df[\"ch_names\"] for channel in channels_list\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channels = dict(counter.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "usage_limit = max([v for k, v in all_channels.items() if \"STI\" not in k])\n",
    "CHANNELS = [k for k, v in all_channels.items() if v >= usage_limit and \"STI\" not in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STIM_CHANNEL = [k for k in all_channels.keys() if \"STI\" in k][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate chunk size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"duration\"] = train_df[\"end\"] - train_df[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "bckg    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "seiz    AxesSubplot(0.125,0.125;0.775x0.755)\n",
       "Name: duration, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.groupby('label')[\"duration\"].plot(kind=\"hist\", bins=np.linspace(0, 50), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_TIME = 1 * CHUNK_FREQUENCY # number of terms per chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split on chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get all file names, randomize them\n",
    "- For each file - split on chunks, randomize them\n",
    "- Get labels for each chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_NUM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fourier_transform(data, window_size=CHUNK_TIME, step_size=CHUNK_TIME // STEPS_NUM):\n",
    "    data = data.T\n",
    "    frequencies = []\n",
    "    for window in range(0, data.shape[0] - window_size, step_size):\n",
    "        chunk = data[window:window + window_size]\n",
    "        frequency_values = np.abs(np.fft.fft(chunk, axis=0))[:window_size // 2]\n",
    "        frequencies.append(frequency_values)\n",
    "    result = np.stack(frequencies)\n",
    "    return result.reshape(result.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, file, channels=CHANNELS, chunk_size=CHUNK_TIME):\n",
    "    annotations = df[\n",
    "        (df[\"full_path\"] == file) & \\\n",
    "        (df[\"label\"] == \"seiz\")\n",
    "    ][[\"start\", \"end\"]]\n",
    "    edf = mne.io.read_raw_edf(file, preload=True, verbose='ERROR')\n",
    "    edf.filter(2, 60)\n",
    "    edf_picks = edf.pick_channels(channels)\n",
    "    data, time = edf_picks[:]\n",
    "        \n",
    "    events = time * 0\n",
    "    for _, (start, end) in annotations.iterrows():\n",
    "        events += (time >= start) & (time <= end)\n",
    "    events = (events > 0).astype(int)\n",
    "    \n",
    "    return data, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_multiple(df, files, channels=CHANNELS, chunk_size=CHUNK_TIME):\n",
    "    total_data = []\n",
    "    total_events = []\n",
    "    for file in tqdm_notebook(files):\n",
    "        data, events = get_data(df, file)\n",
    "        total_data.append(data)\n",
    "        total_events.append(events)\n",
    "    \n",
    "    min_length = min([e.shape[0] for e in total_events])\n",
    "    truncated_length = (min_length // chunk_size) * chunk_size\n",
    "    total_data = [d[:, :truncated_length] for d in total_data]\n",
    "    total_events = [e[:truncated_length] for e in total_events]\n",
    "    \n",
    "    total_data = [\n",
    "        get_fourier_transform(d)\n",
    "        for d in tqdm_notebook(total_data)\n",
    "    ]\n",
    "    \n",
    "    return np.stack(total_data), np.stack(total_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_chunks(data, events, chunk_size=STEPS_NUM):\n",
    "    max_time = max([e.shape[0] for e in events])\n",
    "    while True:\n",
    "        for chunk_start in range(0, max_time - chunk_size, chunk_size):\n",
    "            data_chunk = [d[:, chunk_start:chunk_start + chunk_size].T for d in data]\n",
    "\n",
    "            labels_chunk = [e[chunk_start:chunk_start + chunk_size] for e in events]\n",
    "\n",
    "            yield np.stack(data_chunk), np.stack(labels_chunk)[:, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_files(df, batch_size=BATCH_SIZE):\n",
    "    files = df[\"full_path\"].unique()\n",
    "    files = np.random.choice(files, len(files), replace=False)\n",
    "    for files in zip(*[iter(files)]*batch_size):\n",
    "        yield files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_data_multiple(train_df, train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = next(iterate_files(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, events = get_data(train_df, files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381393207d074eeba99ff0549753b92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe67c17d06a8426e9b88f7547f68b58c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "files = train_df[\"full_path\"].value_counts().index[0:32]\n",
    "data, events = get_data_multiple(train_df, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iterate_chunks(data, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_chunk, labels_chunk = next(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чанк для LSTM: (BATCH_SIZE x CHUNK_TIME x FREQUENCIES * CHANNELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_SIZE = 128\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_FILTERS = (8, 16, 32, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно ли добавить CNN?\n",
    "- Conv1D: (BATCH_SIZE, CHUNK_TIME, CHANNELS) -> (BATCH_SIZE, CHUNK_TIME, CNN_FILTERS)\n",
    "- MaxPool1D: (BATCH_SIZE, CHUNK_TIME, CNN_FILTERS) -> (BATCH_SIZE, CHUNK_TIME // POOL_SIZE, CNN_FILTERS)\n",
    "\n",
    "Продолжать до тех пор, пока чанка не станет достаточного размера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.layers import LSTM,Bidirectional #could try TimeDistributed(Dense(...))\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import optimizers,regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras.backend.tensorflow_backend as KTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(32, kernel_regularizer=<keras.reg..., batch_input_shape=(32, 10, 2...)`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:6: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(64, kernel_regularizer=<keras.reg..., activation=\"relu\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32,W_regularizer=regularizers.l2(l=0.01), batch_input_shape=(BATCH_SIZE, STEPS_NUM, CHUNK_TIME // 2 * len(CHANNELS))))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True, stateful=True)))#, input_shape=(seqlength, features)) ) ### bidirectional ---><---\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(64, activation='relu',W_regularizer=regularizers.l2(l=0.01)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(gamma=2., alpha=.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "        return -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "    return focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam', \n",
    "    metrics=['accuracy', recall_m, precision_m]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit on small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TODO add validation\n",
    "- TODO make batch\n",
    "- TODO speed up iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO make model converge on this batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = iterate_chunks(data, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(generator)\n",
    "x, y_end = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_end.sum() / (y_end > -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (10, 2625) but got array with shape (10, 3060)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-92f1011c083c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (10, 2625) but got array with shape (10, 3060)"
     ]
    }
   ],
   "source": [
    "model.predict(x)[3].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_1_input to have shape (10, 2625) but got array with shape (10, 3060)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-576ef3b12841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_1_input to have shape (10, 2625) but got array with shape (10, 3060)"
     ]
    }
   ],
   "source": [
    "model.evaluate(x, y_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      "32/32 [==============================] - 1s 36ms/step - loss: 2.0413 - accuracy: 0.3500 - recall_m: 0.7114 - precision_m: 0.0271\n",
      "Epoch 2/1000\n",
      "32/32 [==============================] - 1s 21ms/step - loss: 2.0084 - accuracy: 0.5426 - recall_m: 0.7164 - precision_m: 0.0384\n",
      "Epoch 3/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 1.9572 - accuracy: 0.4889 - recall_m: 0.7214 - precision_m: 0.0347\n",
      "Epoch 4/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.9106 - accuracy: 0.4954 - recall_m: 0.7114 - precision_m: 0.0347\n",
      "Epoch 5/1000\n",
      "32/32 [==============================] - 1s 19ms/step - loss: 1.8690 - accuracy: 0.5330 - recall_m: 0.6418 - precision_m: 0.0340\n",
      "Epoch 6/1000\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.8353 - accuracy: 0.5946 - recall_m: 0.5871 - precision_m: 0.0360\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-63ed8590dafe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    182\u001b[0m                         \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                         ins_batch = slice_arrays(\n\u001b[0;32m--> 184\u001b[0;31m                             fit_inputs[:-1], batch_ids) + [fit_inputs[-1]]\n\u001b[0m\u001b[1;32m    185\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                         \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mslice_arrays\u001b[0;34m(arrays, start, stop)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x, y_end, batch_size=x.shape[0], epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_end.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN использовать можно и даже немного нужно\n",
    "А вот seq2seq не надо - у вас же одинаковая длина входа и выхода. Имплементация будет очень похожа не языковую модельку, как была в последней домашке.\n",
    "\n",
    "Если это исследования, а не в прод катить, я бы попробовал LMU и LSTM-SHA из реккурентных и Sparse Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_chunks(size):\n",
    "    return (size // CHUNK_TIME - 1) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ea8d1bbf750490e83e15e8fbfd890a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27463f49be6c46d0b006504b4fe66015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=7.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46e66e03e4a43648c75d1c8f109d176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d13b58a8b3401092a88261ef736136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1eb2058d50b44d98ed54e63385545a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e539d0a4e6434395d8137a8c54085a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=32.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chunk_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-214-775c498674a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber_of_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_events\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         )                \n\u001b[1;32m     16\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m                     \u001b[0;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    709\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \"\"\"\n\u001b[0;32m--> 650\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-197-f2d159e2e4f9>\u001b[0m in \u001b[0;36miterate_chunks\u001b[0;34m(data, events, num_steps)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmax_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk_start\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mdata_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_start\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mchunk_start\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chunk_size' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    for train_files, val_files in tqdm_notebook(list(zip(iterate_files(train_df), iterate_files(val_df)))):\n",
    "        train_data, train_events = get_data_multiple(train_df, train_files)\n",
    "        train_generator = iterate_chunks(train_data, train_events)\n",
    "\n",
    "        val_data, val_events = get_data_multiple(val_df, val_files)\n",
    "        val_generator = iterate_chunks(val_data, val_events)\n",
    "\n",
    "        model.fit_generator(\n",
    "            train_generator, \n",
    "            epochs=1, \n",
    "            steps_per_epoch=number_of_chunks(train_events[0].shape[0]),\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=number_of_chunks(val_events[0].shape[0]) // 10\n",
    "        )                \n",
    "        model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, train_events = get_data_multiple(train_df, train_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Участки с нулевым precision/recall - почему val и train одинаково содержат/не содержат нули? - удалены временно\n",
    "- Высокий precision/recall на валидации не соответствует действительности - проверить!!!!\n",
    "- Влияет ли присутствие одинаковых пациентов/сессий в train/test? - проверить!!!!\n",
    "- Резко падает precision/recall - какие участки дают такой эффект?\n",
    "\n",
    "\n",
    "- Файлы во всю длину, не учитывать loss \n",
    "- Собирать чанки tN файлов в один файл\n",
    "- Переименовывать каналы других интерфейсов\n",
    "- Влияние масштабирования сигнала?\n",
    "\n",
    "\n",
    "- Можно ли использовать чанку большего размера? Можно ли ее предварительно сжать с помощью CNN? Как это повлияет на предсказание?\n",
    "\n",
    "- Применима ли к данным фильтрация? Шум сети/моргания-движения/?\n",
    "- Имеет ли смысл скалировать данные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1739,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_files = next(iterate_files(val_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1740,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_events = get_data_multiple(val_df, val_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предыдущая чанка содержит не нули и единицы, а вероятности. Может быть, добавить пороги?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1717,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df4ea402d72401390a5292fb570dd91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.reset_states()\n",
    "\n",
    "previous_state = np.zeros((BATCH_SIZE, CHUNK_TIME, 1))\n",
    "\n",
    "predicted_states = []\n",
    "true_states = []\n",
    "\n",
    "for (d, _), true_state in tqdm_notebook(iterate_chunks(test_data, test_events)):\n",
    "    current_state = model.predict([d, previous_state])\n",
    "    predicted_states.append(current_state)\n",
    "    true_states.append(true_state)\n",
    "    previous_state = current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_states = np.hstack(true_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 762500, 1)"
      ]
     },
     "execution_count": 1719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_true_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1720,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_states = np.hstack(predicted_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 762500, 1)"
      ]
     },
     "execution_count": 1721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predicted_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16694266393442622"
      ]
     },
     "execution_count": 1722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_true_states > 0.5).sum() / (all_true_states > -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nonzero_index, row in enumerate(all_true_states):\n",
    "    if row.max() > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1724,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.squeeze(all_predicted_states[nonzero_index])\n",
    "true = np.squeeze(all_true_states[nonzero_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1725,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007317321"
      ]
     },
     "execution_count": 1727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[true > 0.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0073153907"
      ]
     },
     "execution_count": 1728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[true < 0.5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f71ff42a710>"
      ]
     },
     "execution_count": 1726,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(pred[true > 0.5], label=\"True\")\n",
    "sns.distplot(pred[true < 0.5], label=\"False\")\n",
    "plt.legend()\n",
    "# plt.xlim(0, 0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare focal loss params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_focal_loss(y_true, y_pred, gamma, alpha):\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    p1 = y_pred[(y_true > 0.5)]\n",
    "    p0 = y_pred[(y_true < 0.5)]\n",
    "    p1_mean = - np.sum(alpha * ((1 - p1) ** gamma) * np.log(p1))\n",
    "    p0_mean = - np.sum((1 - alpha) * (p0 ** gamma) * np.log(1 - p0))\n",
    "    return (p1_mean + p0_mean) / y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 1000\n",
    "y_true = (np.random.rand(shape) < 0.3).astype(float)\n",
    "y_pred_1 = 0.5 * np.ones(y_true.shape)\n",
    "y_pred_2 = 0.1 * np.ones(y_true.shape) # Should be greater than 1\n",
    "y_pred_3 = 0.49 * np.ones(y_true.shape) + (y_true > 0.5) * (0.9 - 0.49) # Should be less than 1\n",
    "y_pred_4 = 0.99 * np.ones(y_true.shape) # Should be greater than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 1\n",
    "alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17328679513998635"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_focal_loss(y_true, y_pred_1, gamma=gamma, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3279382440610576"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_focal_loss(y_true, y_pred_2, gamma=gamma, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11498288055263572"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_focal_loss(y_true, y_pred_3, gamma=gamma, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5660729280736512"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_focal_loss(y_true, y_pred_4, gamma=gamma, alpha=alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare small MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = iterate_chunks(data, events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(generator)\n",
    "x, y = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100), solver=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y = (np.squeeze(y).mean(axis=1) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y.sum() / new_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = x.reshape(32, 250 * 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 100, 100, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(new_x, new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(new_x, new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = eeg_input\n",
    "\n",
    "for cnn_filters in CNN_FILTERS:\n",
    "    feature_extractor = keras.layers.Conv1D(cnn_filters, kernel_size=3, padding=\"same\", activation=\"relu\")(feature_extractor)\n",
    "    feature_extractor = keras.layers.Conv1D(cnn_filters, kernel_size=3, padding=\"same\", activation=\"relu\")(feature_extractor)\n",
    "    feature_extractor = keras.layers.MaxPool1D(pool_size=2, padding=\"same\")(feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, encoder_h_state, encoder_c_state = keras.layers.LSTM(RNN_SIZE, stateful=True, return_state=True)(feature_extractor)\n",
    "\n",
    "events_input = keras.layers.Input(batch_shape=(BATCH_SIZE, CHUNK_TIME, 1), name=\"events\")\n",
    "\n",
    "decoder_outputs, _, _ = keras.layers.LSTM(RNN_SIZE, return_sequences=True, return_state=True)(\n",
    "    events_input, \n",
    "    initial_state=[encoder_h_state, encoder_c_state]\n",
    ")\n",
    "decoder_outputs = keras.layers.Dense(1, activation='sigmoid')(decoder_outputs)\n",
    "\n",
    "model = keras.models.Model(inputs=[eeg_input, events_input], outputs=[decoder_outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from keras.layers import Dense,Activation,Dropout\n",
    "# from keras.layers import LSTM,Bidirectional #could try TimeDistributed(Dense(...))\n",
    "# from keras.models import Sequential, load_model\n",
    "# from keras import optimizers,regularizers\n",
    "# from keras.layers.normalization import BatchNormalization\n",
    "# import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32,W_regularizer=regularizers.l2(l=0.01), batch_input_shape=(BATCH_SIZE, CHUNK_TIME // 2, len(CHANNELS))))\n",
    "# model.add(Bidirectional(LSTM(32, return_sequences=True, stateful=True)))#, input_shape=(seqlength, features)) ) ### bidirectional ---><---\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(64, activation='relu',W_regularizer=regularizers.l2(l=0.01)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def focal_loss(gamma=0, alpha=0.5):\n",
    "#     def focal_loss_fixed(y_true, y_pred):\n",
    "#         pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "#         pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "#         total_sum = - K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \n",
    "#         total_sum -= K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "#         return 2 * total_sum / tf.cast(K.size(y_true), dtype=tf.float32)\n",
    "#     return focal_loss_fixed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
